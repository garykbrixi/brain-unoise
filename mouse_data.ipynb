{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mouse_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1rnxfO73aJZyBrnUuKDsE7JInFxhDpFfG",
      "authorship_tag": "ABX9TyP56rvGlsPxvH8B8gke2BKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garykbrixi/brain-view/blob/master/mouse_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gdPRQgfmilY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5104b95b-5bcc-4500-e306-67139f8e58f4"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "from PIL import Image\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "import pickle\n",
        "\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import average_precision_score"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06NiuwR1YvoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.validation import check_is_fitted, check_array\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "# function for torch PLSR\n",
        "\n",
        "def svd_flip(u, v, u_based_decision=True):\n",
        "    u = u.view(u.size()[0],1)\n",
        "    v = v.view(v.size()[0],1)\n",
        "    if u_based_decision:\n",
        "        # columns of u, rows of v\n",
        "        max_abs_cols = torch.argmax(torch.abs(u), axis=0)\n",
        "        signs = torch.sign(u[list(max_abs_cols), range(u[0].size()[0])])\n",
        "        u *= signs\n",
        "        v *= signs.unsqueeze(1)\n",
        "    else:\n",
        "        # rows of v, columns of u\n",
        "        max_abs_rows = torch.argmax(torch.abs(v), axis=1)\n",
        "        signs = torch.sign(v[range(list(v.size())[0]), max_abs_rows])\n",
        "        u *= signs\n",
        "        v *= signs.unsqueeze(1)\n",
        "    u = u.flatten()\n",
        "    v = v.flatten()\n",
        "    return u, v\n",
        "\n",
        "def _nipals_twoblocks_inner_loop(X, Y, mode=\"A\", max_iter=500, tol=1e-06,\n",
        "                                 norm_y_weights=False):\n",
        "    \"\"\"Inner loop of the iterative NIPALS algorithm.\n",
        "    Provides an alternative to the svd(X'Y); returns the first left and right\n",
        "    singular vectors of X'Y.  See PLS for the meaning of the parameters.  It is\n",
        "    similar to the Power method for determining the eigenvectors and\n",
        "    eigenvalues of a X'Y.\n",
        "    \"\"\"\n",
        "    for col in Y.T:\n",
        "        if torch.any(torch.abs(col) > torch.finfo(torch.float).eps):\n",
        "\n",
        "            y_score = col.detach().view(col.size())\n",
        "\n",
        "            break\n",
        "\n",
        "    x_weights_old = 0\n",
        "    ite = 1\n",
        "    X_pinv = Y_pinv = None\n",
        "    eps = torch.finfo(X.dtype).eps\n",
        "    if mode == \"B\":\n",
        "        # Uses condition from scipy<1.3 in pinv2 which was changed in\n",
        "        # https://github.com/scipy/scipy/pull/10067. In scipy 1.3, the\n",
        "        # condition was changed to depend on the largest singular value\n",
        "        X_t = X.dtype.char.lower()\n",
        "        Y_t = Y.dtype.char.lower()\n",
        "        factor = {'f': 1E3, 'd': 1E6}\n",
        "\n",
        "        cond_X = factor[X_t] * eps\n",
        "        cond_Y = factor[Y_t] * eps\n",
        "\n",
        "    # Inner loop of the Wold algo.\n",
        "    while True:\n",
        "        # 1.1 Update u: the X weights\n",
        "        if mode == \"B\":\n",
        "            if X_pinv is None:\n",
        "                # torch pinverse\n",
        "                X_pinv = torch.pinverse(X, check_finite=False, cond=cond_X)\n",
        "            x_weights = torch.mm(X_pinv, y_score)\n",
        "        else:  # mode\n",
        "            # Mode A regress each X column on y_score\n",
        "            x_weights = torch.mv(X.T, y_score) / torch.dot(y_score.T, y_score)\n",
        "        # If y_score only has zeros x_weights will only have zeros. In\n",
        "        # this case add an epsilon to converge to a more acceptable\n",
        "        # solution\n",
        "        if torch.dot(x_weights.T, x_weights) < eps:\n",
        "            x_weights += eps\n",
        "        # 1.2 Normalize u\n",
        "        x_weights /= torch.sqrt(torch.dot(x_weights.T, x_weights)) + eps\n",
        "        # 1.3 Update x_score: the X latent scores\n",
        "        x_score = torch.mv(X, x_weights)\n",
        "        # 2.1 Update y_weights\n",
        "        if mode == \"B\":\n",
        "            if Y_pinv is None:\n",
        "                # compute once pinv(Y)\n",
        "                Y_pinv = torch.pinverse(Y, check_finite=False, cond=cond_Y)\n",
        "            y_weights = torch.mm(Y_pinv, x_score)\n",
        "        else:\n",
        "            # Mode A regress each Y column on x_score\n",
        "            y_weights = torch.mv(Y.T, x_score) / torch.dot(x_score.T, x_score)\n",
        "        # 2.2 Normalize y_weights\n",
        "        if norm_y_weights:\n",
        "            y_weights /= torch.sqrt(torch.mm(y_weights.T, y_weights)) + eps\n",
        "        # 2.3 Update y_score: the Y latent scores\n",
        "        y_score = torch.mv(Y, y_weights) / (torch.dot(y_weights.T, y_weights) + eps)\n",
        "        # y_score = np.dot(Y, y_weights) / np.dot(y_score.T, y_score) ## BUG\n",
        "        x_weights_diff = x_weights - x_weights_old\n",
        "\n",
        "        if torch.dot(x_weights_diff.T, x_weights_diff) < tol or Y.size()[1] == 1:\n",
        "            break\n",
        "        if ite == max_iter:\n",
        "            warnings.warn('Maximum number of iterations reached',\n",
        "                          ConvergenceWarning)\n",
        "            break\n",
        "        x_weights_old = x_weights\n",
        "        ite += 1\n",
        "    return x_weights, y_weights, ite\n",
        "\n",
        "def _center_scale_xy(X, Y, scale=True):\n",
        "    \"\"\" Center X, Y and scale if the scale parameter==True\n",
        "    Returns\n",
        "    -------\n",
        "        X, Y, x_mean, y_mean, x_std, y_std\n",
        "    \"\"\"\n",
        "    # center\n",
        "    x_mean = torch.mean(X, axis=0)\n",
        "    X -= x_mean\n",
        "    y_mean = torch.mean(Y, axis=0)\n",
        "    Y -= y_mean\n",
        "    # scale\n",
        "    if scale:\n",
        "        x_std = torch.std(X, dim = 0)\n",
        "        x_std[x_std == 0.0] = 1.0\n",
        "        X = X/x_std\n",
        "        y_std = torch.std(Y, dim = 0)\n",
        "        y_std[y_std == 0.0] = 1.0\n",
        "        Y = Y/y_std\n",
        "    else:\n",
        "        x_std = torch.ones(X.size()[1])\n",
        "        y_std = torch.ones(Y.size()[1])\n",
        "    return X, Y, x_mean, y_mean, x_std, y_std\n",
        "\n",
        "class PLS:\n",
        "    def __init__(self, n_components=2, *, scale=True,\n",
        "                 deflation_mode=\"regression\",\n",
        "                 mode=\"A\", algorithm=\"nipals\", norm_y_weights=False,\n",
        "                 max_iter=500, tol=1e-06, copy=True):\n",
        "        self.n_components = n_components\n",
        "        self.deflation_mode = deflation_mode\n",
        "        self.mode = mode\n",
        "        self.norm_y_weights = norm_y_weights\n",
        "        self.scale = scale\n",
        "        self.algorithm = algorithm\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.copy = copy\n",
        "        self.scale = scale\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"Fit model to data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of predictors.\n",
        "        Y : array-like of shape (n_samples, n_targets)\n",
        "            Target vectors, where n_samples is the number of samples and\n",
        "            n_targets is the number of response variables.\n",
        "        \"\"\"\n",
        "        X = X.clone().detach()\n",
        "        Y = Y.clone().detach()\n",
        "        if Y.ndim == 1:\n",
        "            Y = Y.reshape(-1, 1)\n",
        "\n",
        "        n = X.size()[0]\n",
        "        p = X.size()[1]\n",
        "        q = Y.size()[1]\n",
        "\n",
        "        # if self.n_components < 1 or self.n_components > p:\n",
        "        #     raise ValueError('Invalid number of components: %d' %\n",
        "        #                      self.n_components)\n",
        "        # if self.algorithm not in (\"svd\", \"nipals\"):\n",
        "        #     raise ValueError(\"Got algorithm %s when only 'svd' \"\n",
        "        #                      \"and 'nipals' are known\" % self.algorithm)\n",
        "        # if self.algorithm == \"svd\" and self.mode == \"B\":\n",
        "        #     raise ValueError('Incompatible configuration: mode B is not '\n",
        "        #                      'implemented with svd algorithm')\n",
        "        # if self.deflation_mode not in [\"canonical\", \"regression\"]:\n",
        "        #     raise ValueError('The deflation mode is unknown')\n",
        "        # Scale (in place)\n",
        "        X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_ = (\n",
        "            _center_scale_xy(X, Y, self.scale))\n",
        "        # Residuals (deflated) matrices\n",
        "        Xk = X\n",
        "        Yk = Y\n",
        "\n",
        "        # Results matrices\n",
        "        self.x_scores_ = torch.zeros((n, self.n_components))\n",
        "        self.y_scores_ = torch.zeros((n, self.n_components))\n",
        "        self.x_weights_ = torch.zeros((p, self.n_components))\n",
        "        self.y_weights_ = torch.zeros((q, self.n_components))\n",
        "        self.x_loadings_ = torch.zeros((p, self.n_components))\n",
        "        self.y_loadings_ = torch.zeros((q, self.n_components))\n",
        "        self.n_iter_ = []\n",
        "\n",
        "        # NIPALS algo: outer loop, over components\n",
        "        Y_eps = torch.finfo(Yk.dtype).eps\n",
        "\n",
        "        for k in range(self.n_components):\n",
        "\n",
        "            if torch.all(torch.mm(Yk.T, Yk) < torch.finfo(torch.float).eps):\n",
        "                # Yk constant\n",
        "                warnings.warn('Y residual constant at iteration %s' % k)\n",
        "                break\n",
        "            # 1) weights estimation (inner loop)\n",
        "            # -----------------------------------\n",
        "            if self.algorithm == \"nipals\":\n",
        "                # Replace columns that are all close to zero with zeros\n",
        "                Yk_mask = torch.all(torch.abs(Yk) < 10 * Y_eps, axis=0)\n",
        "                Yk[:, Yk_mask] = 0.0\n",
        "\n",
        "                x_weights, y_weights, n_iter_ = \\\n",
        "                    _nipals_twoblocks_inner_loop(\n",
        "                        X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,\n",
        "                        tol=self.tol, norm_y_weights=self.norm_y_weights)\n",
        "                self.n_iter_.append(n_iter_)\n",
        "\n",
        "            elif self.algorithm == \"svd\":\n",
        "                x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)\n",
        "            # Forces sign stability of x_weights and y_weights\n",
        "            # Sign undeterminacy issue from svd if algorithm == \"svd\"\n",
        "            # and from platform dependent computation if algorithm == 'nipals'\n",
        "\n",
        "            x_weights, y_weights = svd_flip(x_weights, y_weights.T)\n",
        "            y_weights = y_weights.T\n",
        "            # columns of u, rows of v\n",
        "            \n",
        "            # compute scores\n",
        "            x_scores = torch.mv(Xk, x_weights)\n",
        "\n",
        "            if self.norm_y_weights:\n",
        "                y_ss = 1\n",
        "            else:\n",
        "                y_ss = torch.dot(y_weights.T, y_weights)\n",
        "\n",
        "            y_scores = torch.mv(Yk, y_weights) / y_ss\n",
        "\n",
        "            # test for null variance\n",
        "            if torch.dot(x_scores.T, x_scores) < torch.finfo(torch.double).eps:\n",
        "                warnings.warn('X scores are null at iteration %s' % k)\n",
        "                break\n",
        "            # 2) Deflation (in place)\n",
        "            # ----------------------\n",
        "            #\n",
        "            # - regress Xk's on x_score\n",
        "\n",
        "            x_loadings = torch.mv(Xk.T, x_scores) / torch.dot(x_scores.T, x_scores)\n",
        "\n",
        "            # - subtract rank-one approximations to obtain remainder matrix\n",
        "\n",
        "            Xk -= x_scores[:, None] * x_loadings.T\n",
        "\n",
        "            if self.deflation_mode == \"canonical\":\n",
        "                # - regress Yk's on y_score, then subtract rank-one approx.\n",
        "                y_loadings = (torch.mv(Yk.T, y_scores)\n",
        "                              / torch.dot(y_scores.T, y_scores))\n",
        "                Yk -= y_scores[:, None] * y_loadings.T\n",
        "            if self.deflation_mode == \"regression\":\n",
        "                # - regress Yk's on x_score, then subtract rank-one approx.\n",
        "                y_loadings = (torch.mv(Yk.T, x_scores)\n",
        "                              / torch.dot(x_scores.T, x_scores))\n",
        "                Yk -= x_scores[:, None] * y_loadings.T\n",
        "            # 3) Store weights, scores and loadings # Notation:\n",
        "\n",
        "            self.x_scores_[:, k] = x_scores.view(-1)  # T\n",
        "            self.y_scores_[:, k] = y_scores.view(-1)  # U\n",
        "            self.x_weights_[:, k] = x_weights.view(-1)  # W\n",
        "            self.y_weights_[:, k] = y_weights.view(-1)  # C\n",
        "            self.x_loadings_[:, k] = x_loadings.view(-1)  # P\n",
        "            self.y_loadings_[:, k] = y_loadings.view(-1)  # Q\n",
        "\n",
        "        # Such that: X = TP' + Err and Y = UQ' + Err\n",
        "\n",
        "        # 4) rotations from input space to transformed space (scores)\n",
        "        # T = X W(P'W)^-1 = XW* (W* : p x k matrix)\n",
        "        # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)\n",
        "        self.x_rotations_ = torch.mm(\n",
        "            self.x_weights_,\n",
        "            torch.pinverse(torch.mm(self.x_loadings_.T, self.x_weights_)))\n",
        "        if Y.size()[1] > 1:\n",
        "            self.y_rotations_ = torch.mm(\n",
        "                self.y_weights_,\n",
        "                torch.pinverse(torch.mm(self.y_loadings_.T, self.y_weights_)))\n",
        "        else:\n",
        "            self.y_rotations_ = torch.ones(1)\n",
        "\n",
        "        if True or self.deflation_mode == \"regression\":\n",
        "            # Estimate regression coefficient\n",
        "            # Regress Y on T\n",
        "            # Y = TQ' + Err,\n",
        "            # Then express in function of X\n",
        "            # Y = X W(P'W)^-1Q' + Err = XB + Err\n",
        "            # => B = W*Q' (p x q)\n",
        "\n",
        "            self.coef_ = torch.mm(self.x_rotations_, self.y_loadings_.T)\n",
        "            self.coef_ = self.coef_\n",
        "            self.y_std_ = self.y_std_\n",
        "            # self.coef_ = torch.mv(self.coef_, self.y_std_)\n",
        "            self.coef_ = self.coef_[:, None] * self.y_std_\n",
        "            self.coef_ = self.coef_[:,0,:]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, Y=None, copy=True):\n",
        "        \"\"\"Apply the dimension reduction learned on the train data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of predictors.\n",
        "        Y : array-like of shape (n_samples, n_targets)\n",
        "            Target vectors, where n_samples is the number of samples and\n",
        "            n_targets is the number of response variables.\n",
        "        copy : boolean, default True\n",
        "            Whether to copy X and Y, or perform in-place normalization.\n",
        "        Returns\n",
        "        -------\n",
        "        x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X, copy=copy, dtype=FLOAT_DTYPES)\n",
        "        # Normalize\n",
        "        X -= self.x_mean_\n",
        "        X /= self.x_std_\n",
        "        # Apply rotation\n",
        "        x_scores = torch.mm(X, self.x_rotations_)\n",
        "        if Y is not None:\n",
        "            Y = check_array(Y, ensure_2d=False, copy=copy, dtype=FLOAT_DTYPES)\n",
        "            if Y.ndim == 1:\n",
        "                Y = Y.reshape(-1, 1)\n",
        "            Y -= self.y_mean_\n",
        "            Y /= self.y_std_\n",
        "            y_scores = torch.mm(Y, self.y_rotations_)\n",
        "            return x_scores, y_scores\n",
        "\n",
        "        return x_scores\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        \"\"\"Transform data back to its original space.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_components)\n",
        "            New data, where n_samples is the number of samples\n",
        "            and n_components is the number of pls components.\n",
        "        Returns\n",
        "        -------\n",
        "        x_reconstructed : array-like of shape (n_samples, n_features)\n",
        "        Notes\n",
        "        -----\n",
        "        This transformation will only be exact if n_components=n_features\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X, dtype=FLOAT_DTYPES)\n",
        "        # From pls space to original space\n",
        "        X_reconstructed = torch.matmul(X, self.x_loadings_.T)\n",
        "\n",
        "        # Denormalize\n",
        "        X_reconstructed *= self.x_std_\n",
        "        X_reconstructed += self.x_mean_\n",
        "        return X_reconstructed\n",
        "\n",
        "    def predict(self, X, copy=True):\n",
        "        \"\"\"Apply the dimension reduction learned on the train data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of predictors.\n",
        "        copy : boolean, default True\n",
        "            Whether to copy X and Y, or perform in-place normalization.\n",
        "        Notes\n",
        "        -----\n",
        "        This call requires the estimation of a p x q matrix, which may\n",
        "        be an issue in high dimensional space.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "        # X = check_array(X, copy=copy, dtype=FLOAT_DTYPES)\n",
        "        # Normalize\n",
        "\n",
        "        X -= self.x_mean_\n",
        "        X /= self.x_std_\n",
        "\n",
        "        Ypred = torch.mm(X, self.coef_)\n",
        "        return Ypred + self.y_mean_\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        \"\"\"Learn and apply the dimension reduction on the train data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of predictors.\n",
        "        y : array-like of shape (n_samples, n_targets)\n",
        "            Target vectors, where n_samples is the number of samples and\n",
        "            n_targets is the number of response variables.\n",
        "        Returns\n",
        "        -------\n",
        "        x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
        "        \"\"\"\n",
        "        return self.fit(X, y).transform(X, y)\n",
        "\n",
        "    def _more_tags(self):\n",
        "        return {'poor_score': True}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-stW8SoV-Mfu",
        "colab_type": "code",
        "outputId": "9eb7289d-f766-43b2-d335-35f3c060de81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare data for analysis\n",
        "PATH = \"drive/My Drive/neuro140/\"\n",
        "infile = open(PATH+'/mouse_brain_data_sample.pkl','rb')\n",
        "mouse_pickle = pickle.load(infile)\n",
        "VISam = mouse_pickle['VISam']\n",
        "print(VISam[118])\n",
        "VISpm = mouse_pickle['VISpm']\n",
        "\n",
        "torch_VISam = torch.tensor(VISam).float()\n",
        "torch_VISpm = torch.tensor(VISpm).float()\n",
        "\n",
        "img_array = np.load(PATH+'/stimulus_set.npy')\n",
        "\n",
        "create_images = False\n",
        "dictlist = []\n",
        "img_names = []\n",
        "for i in range(119):\n",
        "  pngfilename = str(i)+str('.jpg')\n",
        "  if (create_images):\n",
        "    im = Image.fromarray(img_array[i])\n",
        "    im.save(PATH + 'images/' + pngfilename)\n",
        "  row = {'ImageName': pngfilename, 'ImageIndex': i}\n",
        "  img_names.append(pngfilename)\n",
        "  dictlist.append(row)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.120102 0.020811 0.       0.018055 ... 0.008298 0.004659 0.       0.      ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpitqrZ-r4Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get activations from images per model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from fastai.torch_core import flatten_model\n",
        "\n",
        "preprocessing = transforms.Compose([\n",
        "    transforms.Resize((224,224)), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "class SaveFeatures():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = output.clone().detach().requires_grad_(True).cuda()\n",
        "    def close(self):\n",
        "        self.hook.remove()\n",
        "        \n",
        "def get_layer_names(layers):\n",
        "    layer_names = []\n",
        "    for layer in layers:\n",
        "        layer_name = str(layer).split('(')[0]\n",
        "        layer_names.append(layer_name + '-' + str(sum(layer_name in string for string in layer_names) + 1))\n",
        "    return layer_names\n",
        "\n",
        "def get_activations(model, img, layers, target_layer):\n",
        "    img_tensor = preprocessing(img).unsqueeze(0).cuda()\n",
        "    activations = SaveFeatures(layers[target_layer])\n",
        "    model(img_tensor)\n",
        "    activations.close()\n",
        "    return activations.features.detach().cpu().numpy().squeeze()\n",
        "##################################################################\n",
        "\n",
        "res = False\n",
        "alex = False\n",
        "mobile = False\n",
        "inception = False\n",
        "\n",
        "if res:\n",
        "  model = models.resnet18(pretrained=True)\n",
        "  layers = flatten_model(model)\n",
        "  layer_names = get_layer_names(layers)\n",
        "  print(len(layer_names))\n",
        "  print(layer_names)\n",
        "\n",
        "  path = Path(PATH + 'images/')\n",
        "\n",
        "  layer_wise_activation = False\n",
        "  if(layer_wise_activation):\n",
        "    classifier_rdms = {}\n",
        "    for layer_index, layer in enumerate(tqdm(layers[:-2])):\n",
        "        image_activations = []\n",
        "        for image in img_names:\n",
        "            image_array = Image.open(path/image)\n",
        "            # print(get_activations(model, image_array, layers, layer_index).flatten())\n",
        "            image_activations.append(get_activations(model, image_array, layers, layer_index).flatten())\n",
        "        layer_features = np.stack(image_activations)\n",
        "    #save file\n",
        "    with open(PATH + 'classifier_dict.pickle', 'wb') as f:\n",
        "      pickle.dump(classifier_rdms, f)\n",
        "\n",
        "  image_wise_activations = False\n",
        "  if(image_wise_activations):\n",
        "    image_activations = []\n",
        "    for image in img_names:\n",
        "      image_array = Image.open(path/image)\n",
        "      layer_activations = []\n",
        "      for layer_index, layer in enumerate(tqdm(layers[:-2])):\n",
        "        layer_activations.append(get_activations(model, image_array, layers, layer_index))\n",
        "      image_activations.append(layer_activations)\n",
        "    #save file\n",
        "    x = np.array(image_activations)\n",
        "    np.save(str(PATH + 'res18_image_activations.npy'), x, allow_pickle=True)\n",
        "\n",
        "if(alex):\n",
        "  model = models.alexnet(pretrained=True)\n",
        "  layers = flatten_model(model)\n",
        "  layer_names = get_layer_names(layers)\n",
        "  image_activations = []\n",
        "  for image in img_names:\n",
        "    image_array = Image.open(path/image)\n",
        "    layer_activations = []\n",
        "    for layer_index, layer in enumerate(tqdm(layers[:-2])):\n",
        "      layer_activations.append(get_activations(model, image_array, layers, layer_index))\n",
        "    image_activations.append(layer_activations)\n",
        "  x = np.array(image_activations)\n",
        "  np.save(str(PATH + 'alex_image_activations.npy'), x, allow_pickle=True)\n",
        "\n",
        "if(mobile):\n",
        "  model = models.mobilenet_v2(pretrained=True)\n",
        "  layers = flatten_model(model)\n",
        "  layer_names = get_layer_names(layers)\n",
        "  image_activations = []\n",
        "  for image in img_names:\n",
        "    image_array = Image.open(path/image)\n",
        "    layer_activations = []\n",
        "    for layer_index, layer in enumerate(tqdm(layers[:-2])):\n",
        "      layer_activations.append(get_activations(model, image_array, layers, layer_index))\n",
        "    image_activations.append(layer_activations)\n",
        "  x = np.array(image_activations)\n",
        "  np.save(str(PATH + 'mobile_image_activations.npy'), x, allow_pickle=True)\n",
        "\n",
        "inception_image_wise_activations = False\n",
        "if(inception_image_wise_activations):\n",
        "  model = models.inception_v3()(pretrained=True)\n",
        "  layers = flatten_model(model)\n",
        "  layer_names = get_layer_names(layers)\n",
        "  image_activations = []\n",
        "  for image in img_names:\n",
        "    image_array = Image.open(path/image)\n",
        "    layer_activations = []\n",
        "    for layer_index, layer in enumerate(tqdm(layers[:-2])):\n",
        "      layer_activations.append(get_activations(model, image_array, layers, layer_index))\n",
        "    image_activations.append(layer_activations)\n",
        "  x = np.array(image_activations)\n",
        "  np.save(str(PATH + 'inception_image_activations.npy'), x, allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2DP-l-nB-nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#regress from NN layer to predict the neuron\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "def np_12split_PLSR (datasets, layer, savename):\n",
        "  kfold_splits = 12\n",
        "  dataset = np.transpose(datasets)\n",
        "  list_sk = []\n",
        "  corr_list = []\n",
        "  for i in range(len(dataset)):\n",
        "    neuron = dataset[i].reshape(-1, 1)\n",
        "    predictions = np.zeros((119,1))\n",
        "    for split in range(kfold_splits):\n",
        "      test_ind = list(range(split*10, min(split*10+10, 119)))\n",
        "      train_ind = list(set(list(range(0, 119)))^set(test_ind))\n",
        "      Y_test = neuron[test_ind, :]\n",
        "      Y_train = neuron[train_ind, :]\n",
        "      x = layer\n",
        "      X_test = x[test_ind]\n",
        "      X_train = x[train_ind]\n",
        "      clf = PLSRegression(n_components=25).fit(X_train, Y_train)\n",
        "      predictions[test_ind] = clf.predict(X_test)\n",
        "    list_sk.append(predictions)\n",
        "    corr_list.append(np.correlate(predictions.reshape(1,-1)[0],neuron.reshape(1,-1)[0]))\n",
        "  np.save(PATH+savename+'_list_sk.npy', np.array(list_sk))\n",
        "  np.save(PATH+savename+'_corr.npy', np.array(corr_list))\n",
        "\n",
        "def torch_12split_PLSR (datasets, layer, savename):\n",
        "  #pytorch version!\n",
        "  kfold_splits = 12\n",
        "  dataset = datasets.T\n",
        "  list_sk = []\n",
        "  corr_list = []\n",
        "  for i in range(len(dataset)):\n",
        "    neuron = dataset[i].reshape(-1, 1)\n",
        "    predictions = np.zeros((119,1))\n",
        "    for split in range(kfold_splits):\n",
        "      test_ind = list(range(split*10, min(split*10+10, 119)))\n",
        "      train_ind = list(set(list(range(0, 119)))^set(test_ind))\n",
        "      Y_test = neuron[test_ind, :]\n",
        "      Y_train = neuron[train_ind, :]\n",
        "      x = layer\n",
        "      X_test = x[test_ind]\n",
        "      X_train = x[train_ind]\n",
        "      clf = PLS(n_components=25).fit(X_train, Y_train)\n",
        "      predictions[test_ind] = clf.predict(X_test).cpu()\n",
        "    list_sk.append(predictions)\n",
        "    corr_list.append(np.correlate(predictions.reshape(1,-1)[0],np.array(neuron.cpu()).reshape(1,-1)[0]))\n",
        "  np.save(PATH+'torch_'+savename+'_list_sk.npy', np.array(list_sk))\n",
        "  np.save(PATH+\"torch\"+savename+\"_corr.npy\", np.array(corr_list))\n",
        "\n",
        "if res:\n",
        "  image_activations = np.load(str(PATH+'image_activations.npy'), allow_pickle=True)\n",
        "\n",
        "  layer_0 = np.zeros((119, 200704))\n",
        "  torch_layer_0 = torch.zeros((119, 200704)).cuda()\n",
        "  layer_4 = np.zeros((119, 200704))\n",
        "  torch_layer_4 = torch.zeros((119, 200704)).cuda()\n",
        "  layer_48 = np.zeros((119, 25088))\n",
        "  torch_layer_48 = torch.zeros((119, 25088)).cuda()\n",
        "  for i in range(len(image_activations)):\n",
        "    layer_0[i] = image_activations[i][0].flatten()\n",
        "    torch_layer_0[i] = torch.from_numpy(image_activations[i][0]).flatten()\n",
        "    layer_4[i] = image_activations[i][4].flatten()\n",
        "    torch_layer_4[i] = torch.from_numpy(image_activations[i][4]).flatten()\n",
        "    layer_48[i] = image_activations[i][48].flatten()\n",
        "    torch_layer_48[i] = torch.from_numpy(image_activations[i][48]).flatten()\n",
        "\n",
        "if alex:\n",
        "  image_activations = np.load(str(PATH+'alex_image_activations.npy'), allow_pickle=True)\n",
        "  \n",
        "  alex_0 = np.zeros((119, 193600))\n",
        "  torch_alex_0 = torch.zeros((119, 193600)).cuda()\n",
        "  alex_3 = np.zeros((119, 139968))\n",
        "  torch_alex_3 = torch.zeros((119, 139968)).cuda()\n",
        "  alex_6 = np.zeros((119, 64896))\n",
        "  torch_alex_6 = torch.zeros((119, 64896)).cuda()\n",
        "  alex_8 = np.zeros((119, 43264))\n",
        "  torch_alex_8 = torch.zeros((119, 43264)).cuda()\n",
        "  alex_10 = np.zeros((119, 43264))\n",
        "  torch_alex_10 = torch.zeros((119, 43264)).cuda()\n",
        "  for i in range(len(image_activations_alex)):\n",
        "    alex_0[i] = image_activations[i][0].flatten()\n",
        "    torch_alex_0[i] = torch.from_numpy(image_activations[i][0]).flatten().float()\n",
        "    alex_3[i] = image_activations[i][3].flatten()\n",
        "    torch_alex_3[i] = torch.from_numpy(image_activations[i][3]).flatten().float()\n",
        "    alex_6[i] = image_activations[i][6].flatten()\n",
        "    torch_alex_6[i] = torch.from_numpy(image_activations[i][6]).flatten().float()\n",
        "    alex_8[i] = image_activations[i][8].flatten()\n",
        "    torch_alex_8[i] = torch.from_numpy(image_activations[i][8]).flatten().float()\n",
        "    alex_10[i] = image_activations[i][10].flatten()\n",
        "    torch_alex_10[i] = torch.from_numpy(image_activations[i][10]).flatten().float()\n",
        "\n",
        "if mobile:\n",
        "  image_activations_alex = np.load(str(PATH+'mobile_image_activations.npy'), allow_pickle=True)\n",
        "  \n",
        "  mobile_0 = np.zeros((119, 802816))\n",
        "  torch_mobile_0 = torch.zeros((119, 802816)).cuda()\n",
        "  # mobile_3 = np.zeros((119, 200704))\n",
        "  # torch_mobile_3 = torch.zeros((119, 200704)).cuda()\n",
        "  # mobile_6 = np.zeros((119, 200704))\n",
        "  # torch_mobile_6 = torch.zeros((119, 200704)).cuda()\n",
        "  mobile_8 = np.zeros((119, 200704))\n",
        "  torch_mobile_8 = torch.zeros((119, 200704)).cuda()\n",
        "  for i in range(len(image_activations_alex)):\n",
        "    mobile_0[i] = image_activations_res[i][0].flatten()\n",
        "    torch_mobile_0[i] = torch.from_numpy(image_activations_res[i][0]).flatten().float()\n",
        "    mobike_8[i] = image_activations_res[i][8].flatten()\n",
        "    torch_mobile_8[i] = torch.from_numpy(image_activations_res[i][8]).flatten().float()\n",
        "\n",
        "if res:\n",
        "  np_12split_PLSR(VISam, layer_4, 'res18_4_VISam')\n",
        "\n",
        "  np_12split_PLSR(VISam, layer_48, 'res18_48_VISam')\n",
        "\n",
        "  np_12split_PLSR(VISam, layer_4, 'res18_4_VISpm')\n",
        "\n",
        "  np_12split_PLSR(VISam, layer_4, 'res18_48_VISpm')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISam, torch_layer_4, 'torch_res18_4_VISam')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISam, torch_layer_48, 'torch_res18_48_VISam')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISpm, torch_layer_4, 'torch_res18_4_VISpm')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISpm, torch_layer_48, 'torch_res18_48_VISpm')\n",
        "\n",
        "if alex:\n",
        "  # np_12split_PLSR(VISam, alex_0, 'alex_0_VISam')\n",
        "\n",
        "  # np_12split_PLSR(VISam, alex_3, 'alex_3_VISam')\n",
        "\n",
        "  # np_12split_PLSR(VISam, alex_10, 'alex_10_VISam')\n",
        "\n",
        "  # np_12split_PLSR(VISpm, alex_0, 'alex_0_VISpm')\n",
        "\n",
        "  # np_12split_PLSR(VIpam, alex_3, 'alex_3_VISpm')\n",
        "\n",
        "  # np_12split_PLSR(VISpm, alex_10, 'alex_10_VISpm')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISam, torch_alex_0, 'torch_alex_0_VISam')\n",
        "\n",
        "  torch_12split_PLSR(VISam, torch_alex_3, 'torch_alex_3_VISam')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISam, torch_alex_10, 'alex_10_VISam')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISpm, torch_alex_0, 'alex_0_VISpm')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISpm, torch_alex_3, 'torch_alex_3_VISpm')\n",
        "\n",
        "  torch_12split_PLSR(torch_VISpm, torch_alex_10, 'alex_10_VISpm')\n",
        "\n",
        "if mobile:\n",
        "  np_12split_PLSR(VISam, mobile_0, 'mobile_0_VISam')\n",
        "\n",
        "  np_12split_PLSR(VISam, mobile_8, 'mobile_8_VISam')\n",
        "\n",
        "  np_12split_PLSR(VISpm, mobile_0, 'mobile_0_VISpm')\n",
        "\n",
        "  np_12split_PLSR(VISpm, mobile_8, 'mobile_8_VISpm')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4rZj7vdNJVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "61f9b2bf-3ba7-4119-e86d-f1a266bbb261"
      },
      "source": [
        "res18_4_corr = np.load(PATH+'torch_res18_3_VISam_corr.npy')\n",
        "print('res18 4 sam')\n",
        "print(np.average(res18_4_corr))\n",
        "res18_corr = np.load(PATH+'res18_48_VISam_corr.npy')\n",
        "print('res18 48 sam')\n",
        "print(np.average(res18_corr))\n",
        "res18_4_corr = np.load(PATH+'torchtorch_res18_4_VISpm_corr.npy')\n",
        "print('res18 4 spm')\n",
        "print(np.average(res18_4_corr))\n",
        "res18_48_corr = np.load(PATH+'res18_48_VISpm_corr.npy')\n",
        "print('res18 48 spm')\n",
        "print(np.average(res18_48_corr))\n",
        "\n",
        "corr = np.load(PATH+'alex_0_VISam_corr.npy')\n",
        "print('alex 0 sam')\n",
        "print(np.average(corr))\n",
        "corr = np.load(PATH+'torchalex_10_VISam_corr.npy')\n",
        "print('alex 10 sam')\n",
        "print(np.average(corr))\n",
        "\n",
        "corr = np.load(PATH+'torchalex_0_VISpm_corr.npy')\n",
        "print('alex 0 spm')\n",
        "print(np.average(corr))\n",
        "corr = np.load(PATH+'torchalex_10_VISpm_corr.npy')\n",
        "print('alex 10 spm')\n",
        "print(np.average(corr))\n",
        "\n",
        "corr_dict = {}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "res18 4 sam\n",
            "0.21279011529734965\n",
            "res18 48 sam\n",
            "0.18767793624548623\n",
            "res18 4 spm\n",
            "0.16978219607235842\n",
            "res18 48 spm\n",
            "0.14796026100829673\n",
            "alex 0 sam\n",
            "0.21279016089904032\n",
            "alex 10 sam\n",
            "0.24477178764847266\n",
            "alex 0 spm\n",
            "0.10018296656487818\n",
            "alex 10 spm\n",
            "0.18821280066774534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOme331OosAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#benchmarking: PLSR\n",
        "#using layer 4 of resnet 18, VISam neurons, all images\n",
        "# x dim : 119, \n",
        "\n",
        "if (res):\n",
        "  layer_4 = layer_4.astype(np.float32)\n",
        "  VISam = VISam.astype(np.float32)\n",
        "\n",
        "  # print(layer_4.shape)\n",
        "  # print(torch_layer_4.size())\n",
        "\n",
        "  # for i in range(11):\n",
        "  #   # index = list(range(i*10 + 9))\n",
        "  #   index = list(range(119))\n",
        "  #   #torch version:\n",
        "    # %timeit PLS(n_components=25).fit(torch_layer_4[index], torch_VISam[index, :])\n",
        "  #   #scikit\n",
        "  #   %timeit PLSRegression(n_components=25).fit(layer_4[index], VISam[index, :])\n",
        "\n",
        "  # check equality\n",
        "  equality_check = True\n",
        "  if equality_check:\n",
        "    index = list(range(118))\n",
        "    train = 119\n",
        "    print(torch_layer_4)\n",
        "    modl = PLS(n_components=25).fit(torch_layer_4[index], torch_VISam[index, :])\n",
        "    torch_ans = modl.predict(torch_layer_4[train])\n",
        "    modl = PLSRegression(n_components=25).fit(layer_4[index], VISam[index, :])\n",
        "    sk_ans = modl.predict(layer_4[train])\n",
        "    print(torch_ans)\n",
        "    print(sk_ans)\n",
        "    # assert torch_ans == sk_ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO8UdbRW-OXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cov(x, rowvar = False):\n",
        "  if not rowvar:\n",
        "    x = x.t()\n",
        "  f = 1.0 / (x.size(1) - 1)\n",
        "  x -= torch.mean(x, dim=1, keepdim=True)\n",
        "  xt = x.t()\n",
        "  c = f * x.matmul(xt).squeeze()\n",
        "  return c\n",
        "\n",
        "\n",
        "def PCA(data, dims = 2):\n",
        "  \"\"\"\n",
        "  based on numpy function:\n",
        "  https://stackoverflow.com/questions/13224362/principal-component-analysis-pca-in-python\n",
        "  \"\"\"\n",
        "  n = data.shape\n",
        "  mx = torch.mean(data, dim=0)\n",
        "\n",
        "  x = data - mx\n",
        "  R = cov(x, False)\n",
        "\n",
        "  evals, evecs = torch.symeig(R_t, eigenvectors = True, upper = True)\n",
        "  \n",
        "  idx = torch.argsort(evals, descending = True)\n",
        "  evecs = evecs[:,idx]\n",
        "  evals = evals[idx]\n",
        "\n",
        "  evecs = evecs[:, :dims]\n",
        "\n",
        "  return torch.mm(evecs.T, data.T).T, evals, evecs\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA as PCA_sk\n",
        "\n",
        "pca = PCA_sk(n_components=5)\n",
        "pca.fit(VISam)\n",
        "Sam_c = pca.components_\n",
        "print(Sam_c)\n",
        "\n",
        "pca = PCA_sk(n_components=5)\n",
        "pca.fit(VIspm)\n",
        "Spm_c = pca.components_\n",
        "print(Spm_c)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}